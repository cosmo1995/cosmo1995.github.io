<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>hmm on Cosmo</title>
    <link>https://cosmo1995.github.io/tags/hmm/</link>
    <description>Recent content in hmm on Cosmo</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 12 Mar 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://cosmo1995.github.io/tags/hmm/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>HMM-GMM和HMM-DNN</title>
      <link>https://cosmo1995.github.io/p/hmm-gmm%E5%92%8Chmm-dnn/</link>
      <pubDate>Fri, 12 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://cosmo1995.github.io/p/hmm-gmm%E5%92%8Chmm-dnn/</guid>
      <description>HMM-GMM模型 模型分析 原始音频信号经过【预加重-分帧-加窗-fft-mel滤波-DCT】，得到MFCC特征作为输入信号。假设有一段80帧的语音，内容为&amp;quot;six&amp;quot;，对应的音素为“S IH K S”，提取MFCC后的80帧特征序列就是观察序列：
$$ O = [o_1,o_2,&amp;hellip;,o_T],\ T=80 $$ 给定观察序列$O$，估计HMM-GMM模型的参数，这就是HMM中的训练问题。
 输入：$O = [o_1,o_2,&amp;hellip;,o_T]$，即80帧MFCC特征 目标：估计HMM-GMM模型参数$\lambda=(A,B)$，使得$P(O|\lambda)$值最大 输出：通过模型计算每一帧属于S IH K S这四个音素中某一个状态(3状态)的概率  A是状态转移概率，B是观察概率，也就是发射概率。我们使用GMM对发射概率建模，所以HMM-GMM模型的参数：
 HMM参数：状态转移概率 GMM参数：高斯分量系数、均值向量和协方差矩阵  同时，需要额外说明的是：HMM-GMM模型的训练是无监督的，因为我们并不知道哪一帧输入特征对应哪个音素的哪一个状态。训练的目的就是找到帧对应状态的情况，并更新状态的模型参数。把每一帧都归到某个状态上，本质上是进行聚类，是无监督训练。
单音素GMM-HMM模型的训练通过Viterbi训练(嵌入式训练)，把“S IH K S”对应的GMM模型嵌入到整段音频中去训练。
模型训练 对于HMM和GMM这种含有隐变量的模型，我们使用EM算法进行训练。训练的步骤如下图：

初始化GMM 根据topo和sets.int确定GMM的数量，每个GMM初始均为单高斯。
初始化对齐 初始化对齐的目的是为Viterbi对齐提供初始参数A、B。
一开始不知道一段语音的哪些帧对应哪些状态，我们就进行平均分配。前面提到的“six”语音一共80帧，包含四个音素“S IH K S”，每个音素分配到20帧，每个音素又由三个状态组成，每个状态分配6或者7帧。这样就初始化了每个状态对应的输入数据。
如下图，平均对齐后，前1-20帧数据对应“S”音素，21-40帧数据对应“IH”音素，41-60帧对应“K”音素，61-80对应“S”音素。

初始化模型 HMM-GMM模型参数$λ=(A,B,\Pi)$。
 $A$：在初始化对齐后就可以统计出状态1-&amp;gt;状态1的转移次数，状态1-&amp;gt;状态2的转移次数，转移次数/总转移次数就是转移概率。 $B$：更新GMM参数 [见https://cosmo1995.github.io/p/kaldi%E6%BA%90%E7%A0%81%E4%B9%8Bgmm_2/] $\Pi$：就是[1,0,0,0&amp;hellip;]，一开始在状态1的概率是100%。在语音识别应用中由于HMM是从左到右的模型，第一个必然是状态1，即$P(q_0=1)=1$。所以没有$\Pi$这个参数了。  重新对齐 需要向真实情况逼近的重新对齐。Viterbi算法根据初始化模型$λ=(A,B,Π)$来计算。它记录每个时刻的每个可能状态的之前最优路径概率，同时记录最优路径的前一个状态，不断向后迭代，找出最后一个时间点的最大概率值对应的状态，再向前回溯到起点，得到最优路径。
得到最优路径就得到最优的状态转移情况，哪些帧对应哪些状态就变了。转移概率$A$就变了。哪些帧对应哪些状态变了导致状态对应的GMM参数自然就变了，即发射概率$B$变了。
迭代 新的$A$和新的$B$又可以进行下一次的Viterbi算法，寻找新的最优路径，得到新的对齐，新的对齐继续改变着参数$A$、$B$。如此循环迭代直到收敛或者达到固定的轮数，则GMM-HMM模型训练完成。
HMM-DNN模型 HMM-GMM建模能力有限，无法准确的表征语音内部复杂的结构，所以识别率低。随着深度学习的崛起，研究人员将其逐步应用于语音识别中。最开始便是DNN代替了GMM来进行观察状态概率的输出，实现HMM-DNN声学模型框架，大大提高了识别率。
GMM与DNN对比 HMM-DNN用DNN替换了GMM来对输入语音信号的观察概率进行建模。
  GMM为了减少参数量，一般使用对角协方差矩阵建模，要求特征维度间的独立性，因此GMM使用的特征是MFCC，这个特征已经做了去相关性处理；DNN使用的特征是FBank，这个特征保持着相关性。
  GMM是生成模型，采用无监督学习；DNN是判别模型，采用有监督学习。</description>
    </item>
    
    <item>
      <title>Kaldi源码之hmm</title>
      <link>https://cosmo1995.github.io/p/kaldi%E6%BA%90%E7%A0%81%E4%B9%8Bhmm/</link>
      <pubDate>Wed, 08 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://cosmo1995.github.io/p/kaldi%E6%BA%90%E7%A0%81%E4%B9%8Bhmm/</guid>
      <description>kaldi中TransitionModel用来更新HMM的转移概率，通过hmm-topology描述每个phone的拓扑结构，包括phone对应的state和以及state之间的初始转移概率。通过transition-model定义了transition的基本单元transition-state和转移路径transition-id。
hmm-topology 以yesno的topo为例，yesno中有三个音素：SIL、Y、N ，phone id 分别为1、2、3。其中SIL有0~4共5个状态，5为non-emitting。yes/no均含有0~2共3个状态，3为non-emitting。topo中还定义了每个phone对应的状态之间的初始转移概率。
Kaldi通过HmmTopology类表示topo结构，在HmmTopology中定义了HmmState结构体来描述HMM-state，包含HMM-state对应的pdf-class和转移的目标状态、初始转移概率。
struct HmmState { int32 pdf_class; std::vector&amp;lt;std::pair&amp;lt;int32, BaseFloat&amp;gt; &amp;gt; transitions; ... } typedef std::vector&amp;lt;HmmState&amp;gt; TopologyEntry; TopologyEntry中包含一个phone对应的所有HMM-state以及这些HMM-state之间的转移路径和转移概率，即一个phone的完整topo结构。
hmm-topology的成员变量为：
std::vector&amp;lt;int32&amp;gt; phones_; std::vector&amp;lt;int32&amp;gt; phone2idx_; std::vector&amp;lt;TopologyEntry&amp;gt; entries_; hmm-topology类包含了上图中完整的topo信息，包括所有音素、每个音素对应的HMM-state和HMM-state间的转移路径和转移概率。
transition-model transition中相关的概念：
 phone：音素，id是从1开始的整数。 HMM-state：每个音素的state的id，从0开始的整数。 pdf-id：每个state相对应的GMM概率密度函数id，这个值是全局唯一从0开始的整数。在triphone中，pdf-id会替换为决策树聚类后的实际pdf-id。pdf-id又可以分为forward-pdf-id和self-loop-pdf-id，默认pdf-id=forward-pdf-id=self-loop-pdf-id。 transition-state：抽象出来的转移状态，对于monophone，和HMM-state一一对应；对于triphone，对应于上下文音素绑定的状态。用(phone,HMM-state,pdf-id)表示，从1开始。 transition-index：表示一个transition-state的转移路径的index，在每个状态内从0开始的整数。 transition-id：所有transition-state的转移路径的id，全局唯一从1开始的整数，跟(transition-state,transition-index)一一对应。  通过show-transitions可以查看这些变量的具体值，如下表。
transition-model中定义了triples,state2id_和id2state，分别表示transition-state对应的triples，每个transition-state对应的的第一个transition-id，每个transition-id对应的transition-state。
std::vector&amp;lt;Triple&amp;gt; triples_; // indexed by transition-state - 1 std::vector&amp;lt;int32&amp;gt; state2id_; // indexed by transition-state std::vector&amp;lt;int32&amp;gt; id2state_; // indexed by transition-id ... 通过这三个变量，transition-model中实现了一系列transition概念的转换，包括：
(phone, HMM-state, pdf-id) &amp;lt;&amp;mdash;&amp;gt; transition-state
(transition-state, transition-index) &amp;lt;&amp;mdash;&amp;gt; transition-id</description>
    </item>
    
  </channel>
</rss>
