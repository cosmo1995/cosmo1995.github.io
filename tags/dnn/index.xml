<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>dnn on Cosmo</title>
    <link>https://cosmo1995.github.io/tags/dnn/</link>
    <description>Recent content in dnn on Cosmo</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 12 Mar 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://cosmo1995.github.io/tags/dnn/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>HMM-GMM和HMM-DNN</title>
      <link>https://cosmo1995.github.io/p/hmm-gmm%E5%92%8Chmm-dnn/</link>
      <pubDate>Fri, 12 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://cosmo1995.github.io/p/hmm-gmm%E5%92%8Chmm-dnn/</guid>
      <description>HMM-GMM模型 模型分析 原始音频信号，经过【预加重-分帧-加窗-fft-mel滤波器组-DCT】，得到MFCC特征作为输入信号。假设有一句80帧的原始语音，这80帧特征序列就是观察序列：
$$ O = [o_1,o_2,&amp;hellip;,o_T],\ T=80 $$ 给定观察序列$O$，估计HMM-GMM模型的参数，这就是HMM中的训练问题。
 输入：$O = [o_1,o_2,&amp;hellip;,o_T]$，即80帧MFCC特征 目标：估计HMM-GMM模型参数$\lambda=(A,B)$，使得$P(O|\lambda)$值最大 输出：通过模型计算每一帧属于S IH K S这四个音素中某一个状态(3状态)的概率  A是状态转移概率，B是观察概率，也就是发射概率。我们使用GMM模型对观察概率建模，所以HMM-GMM模型的参数：
 HMM参数：状态转移概率 GMM参数：高斯分量系数、均值向量和协方差矩阵  同时，需要额外说明的是：HMM-GMM模型的训练是无监督的。因为我们并不知道哪一帧输入特征对应哪个音素的哪一个状态。训练的目的就是找到帧对应状态的情况，并更新状态的gmm参数。把每一帧都归到某个状态上，本质上是进行聚类，是无监督训练。
单音素GMM-HMM模型的训练通过Viterbi训练(嵌入式训练)，把“S IH K S”对应的GMM模型嵌入到整段音频中去训练。
模型训练 对于HMM和GMM这种含有隐变量的模型，我们使用EM算法进行训练。训练的步骤如下图：

初始化对齐 初始化对齐的目的是为Viterbi对齐提供初始参数A、B。
一开始不知道一段语音的哪些帧对应哪些状态，我们就进行平均分配。前面提到的“ six”语音一共80帧，包含四个音素“S IH K S”，每个音素分配到20帧，每个音素又有三个状态组成，每个状态分配6或者7帧。这样就初始化了每个状态对应的输入数据。
就是假设前0-20帧数据都是“S”这个音素的发音，20-40帧数据都是“IH”这个音素的发音，40-60帧是“K”这个音素的发音，60-80是“S”这个音素的发音。但这只是一个假设，事实到底如此我们还不知道。我们可以在这个初始对齐下进一步优化。
初始化模型 HMM模型参数$λ=(A,B,\Pi)$。
 $A$：在初始化对齐后就可以统计出状态1-&amp;gt;状态1的转移次数，状态1-&amp;gt;状态2的转移次数，转移次数/总转移次数就是转移概率。 $B$：初始化后，状态1对应前6帧数据，根据这6帧数据来计算状态1对应的GMM模型参数，得到初始均值向量和协方差矩阵 。K-Means来初始化GMM的高斯分量系数。 $\Pi$：就是[1,0,0,0&amp;hellip;]，一开始在状态1的概率是100%。在语音识别应用中由于HMM是从左到右的模型，第一个必然是状态1，即$P(q_0=1)=1$。所以没有$\Pi$这个参数了。  重新对齐 需要重新对齐，向真实情况逼近的重新对齐。viterbi算法根据初始化模型$λ=(A,B,Π)$来计算。它记录每个时刻的每个可能状态的之前最优路径概率，同时记录最优路径的前一个状态，不断向后迭代，找出最后一个时间点的最大概率值对应的状态，如何向前回溯，得到最优路径。得到最优路径就得到最优的状态转移情况，哪些帧对应哪些状态就变了。
转移概率A就变了。哪些帧对应哪些状态变了导致状态对应的GMM参数自然就变了，也可以跟着更新均值 和方差，即发射概率B变了。
迭代 新的A和新的B又可以进行下一次的Viterbi算法，寻找新的最优路径，得到新的对齐，新的对齐继续改变着参数A、B。如此循环迭代直到收敛或者达到固定的轮数，则GMM-HMM模型训练完成。
HMM-DNN模型 HMM-GMM建模能力有限，无法准确的表征语音内部复杂的结构，所以识别率低。随着深度学习的崛起，研究人员将其逐步应用于语音识别中。最开始便是DNN代替了GMM来进行观察状态概率的输出，实现HMM-DNN声学模型框架，大大提高了识别率。
GMM与DNN对比 HMM-DNN用DNN替换了GMM来对输入语音信号的观察概率进行建模。
  GMM为了减少参数量，一般使用对角协方差矩阵建模，要求特征维度间的独立性，因此GMM使用的特征是MFCC，这个特征已经做了去相关性处理；DNN使用的特征是FBank，这个特征保持着相关性。
  GMM是生成模型，采用无监督学习；DNN是判别模型，采用有监督学习。
  
（DNN输入可采用连续的拼接帧）</description>
    </item>
    
  </channel>
</rss>
